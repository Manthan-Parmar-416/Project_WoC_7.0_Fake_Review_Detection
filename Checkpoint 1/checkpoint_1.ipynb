{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Checkpoint 1: Data Preprocessing for Fake Review Detection**\n",
    "### Manthan Parmar 202201416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n",
    "\n",
    "- **Handling missing values** by filling or removing incomplete data entries.\n",
    "- **Removing duplicates** and irrelevant data (e.g., spam or unrelated reviews).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('fakeReviewData.csv')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Doing the check for missing values in the data entry.\n",
    "missing_count = df.isna().sum().sum()\n",
    "print(missing_count)\n",
    "# There is no missing data in in the data given to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#Doing the check for duplicate values in the data entry.\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(duplicate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>Sports_and_Outdoors_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This is a really good starter kit, with lots o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>Sports_and_Outdoors_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This is a really good starter kit, with lots o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>Sports_and_Outdoors_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Great, no complaints. Comfortable, phone fits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>Sports_and_Outdoors_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Great, no complaints. Comfortable, phone fits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12289</th>\n",
       "      <td>Movies_and_TV_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>One of the best movies of the year.  Not for e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548</th>\n",
       "      <td>Movies_and_TV_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>One of the best movies of the year.  Not for e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19638</th>\n",
       "      <td>Pet_Supplies_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>My dog loves these and it has kept her occupie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19802</th>\n",
       "      <td>Pet_Supplies_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>My dog loves these and it has kept her occupie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19803</th>\n",
       "      <td>Pet_Supplies_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>My dog loves it and it has kept her occupied f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20242</th>\n",
       "      <td>Pet_Supplies_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>My dog loves it and it has kept her occupied f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22294</th>\n",
       "      <td>Pet_Supplies_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>Got these to give to my 8 mth old chihuahua wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22305</th>\n",
       "      <td>Pet_Supplies_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>Got these to give to my 8 mth old chihuahua wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>Kindle_Store_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I received this story as an ARC in exchange fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26444</th>\n",
       "      <td>Kindle_Store_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I received this story as an ARC in exchange fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27232</th>\n",
       "      <td>Kindle_Store_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This is the first book in a series by the auth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27233</th>\n",
       "      <td>Kindle_Store_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This is the first book in a series by the auth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29091</th>\n",
       "      <td>Books_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I really enjoyed this book. The characters wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29203</th>\n",
       "      <td>Books_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I really enjoyed this book. The characters wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33208</th>\n",
       "      <td>Toys_and_Games_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I got this for my son for Christmas.  He loved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33602</th>\n",
       "      <td>Toys_and_Games_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I got this for my son for Christmas.  He loved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>Toys_and_Games_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I bought this for my son for Christmas.  He lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34795</th>\n",
       "      <td>Toys_and_Games_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I bought this for my son for Christmas.  He lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37296</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I bought this for a Halloween costume and it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37543</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I bought this for a Halloween costume and it w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "6018          Sports_and_Outdoors_5     5.0    CG   \n",
       "6025          Sports_and_Outdoors_5     5.0    CG   \n",
       "6706          Sports_and_Outdoors_5     5.0    CG   \n",
       "6708          Sports_and_Outdoors_5     5.0    CG   \n",
       "12289               Movies_and_TV_5     5.0    CG   \n",
       "12548               Movies_and_TV_5     5.0    CG   \n",
       "19638                Pet_Supplies_5     5.0    CG   \n",
       "19802                Pet_Supplies_5     5.0    CG   \n",
       "19803                Pet_Supplies_5     5.0    CG   \n",
       "20242                Pet_Supplies_5     5.0    CG   \n",
       "22294                Pet_Supplies_5     5.0    OR   \n",
       "22305                Pet_Supplies_5     5.0    OR   \n",
       "26399                Kindle_Store_5     5.0    CG   \n",
       "26444                Kindle_Store_5     5.0    CG   \n",
       "27232                Kindle_Store_5     5.0    CG   \n",
       "27233                Kindle_Store_5     5.0    CG   \n",
       "29091                       Books_5     5.0    CG   \n",
       "29203                       Books_5     5.0    CG   \n",
       "33208              Toys_and_Games_5     5.0    CG   \n",
       "33602              Toys_and_Games_5     5.0    CG   \n",
       "34788              Toys_and_Games_5     5.0    CG   \n",
       "34795              Toys_and_Games_5     5.0    CG   \n",
       "37296  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "37543  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "\n",
       "                                                   text_  \n",
       "6018   This is a really good starter kit, with lots o...  \n",
       "6025   This is a really good starter kit, with lots o...  \n",
       "6706   Great, no complaints. Comfortable, phone fits ...  \n",
       "6708   Great, no complaints. Comfortable, phone fits ...  \n",
       "12289  One of the best movies of the year.  Not for e...  \n",
       "12548  One of the best movies of the year.  Not for e...  \n",
       "19638  My dog loves these and it has kept her occupie...  \n",
       "19802  My dog loves these and it has kept her occupie...  \n",
       "19803  My dog loves it and it has kept her occupied f...  \n",
       "20242  My dog loves it and it has kept her occupied f...  \n",
       "22294  Got these to give to my 8 mth old chihuahua wh...  \n",
       "22305  Got these to give to my 8 mth old chihuahua wh...  \n",
       "26399  I received this story as an ARC in exchange fo...  \n",
       "26444  I received this story as an ARC in exchange fo...  \n",
       "27232  This is the first book in a series by the auth...  \n",
       "27233  This is the first book in a series by the auth...  \n",
       "29091  I really enjoyed this book. The characters wer...  \n",
       "29203  I really enjoyed this book. The characters wer...  \n",
       "33208  I got this for my son for Christmas.  He loved...  \n",
       "33602  I got this for my son for Christmas.  He loved...  \n",
       "34788  I bought this for my son for Christmas.  He lo...  \n",
       "34795  I bought this for my son for Christmas.  He lo...  \n",
       "37296  I bought this for a Halloween costume and it w...  \n",
       "37543  I bought this for a Halloween costume and it w...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = df[df.duplicated(keep = False)]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We use a different data frame without the duplicate rows for further processing.\n",
    "df2 = df.drop_duplicates()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_2 = df2.duplicated().sum()\n",
    "print(duplicate_count_2)\n",
    "#Now, there are no duplicate rows present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Normalization**\n",
    "\n",
    "- **Converting all text to lowercase** to maintain uniformity.\n",
    "- **Removing punctuation, special characters, and numbers** where not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this!  well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back. i love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set. good quality. we have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  love this!  well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  i...  \n",
       "2  this pillow saved my back. i love the look and...  \n",
       "3  missing information on how to use it, but it i...  \n",
       "4  very nice set. good quality. we have had the s...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert all text to lowercase\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3['text_'] = df3['text_'].str.lower()\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  love this  well made sturdy and very comfortab...  \n",
       "1  love it a great upgrade from the original  ive...  \n",
       "2  this pillow saved my back i love the look and ...  \n",
       "3  missing information on how to use it but it is...  \n",
       "4  very nice set good quality we have had the set...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation, special characters and numbers\n",
    "#Using regex for simplicity\n",
    "df4 = df3.copy()\n",
    "\n",
    "df4['text_'] = df4['text_'].str.replace('[^a-zA-Z\\\\s]','',regex=True)\n",
    "df4.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Tokenization**\n",
    "\n",
    "- **Breaking down sentences into individual words or tokens** for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [love, this, well, made, sturdy, and, very, co...\n",
       "1    [love, it, a, great, upgrade, from, the, origi...\n",
       "2    [this, pillow, saved, my, back, i, love, the, ...\n",
       "3    [missing, information, on, how, to, use, it, b...\n",
       "4    [very, nice, set, good, quality, we, have, had...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Break down sentences to individual words, or tokens.\n",
    "df5 = df4.copy()\n",
    "\n",
    "df5['tokens'] = df5['text_'].apply(lambda x: x.split())\n",
    "df5['tokens'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>[love, this, well, made, sturdy, and, very, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, origi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>[this, pillow, saved, my, back, i, love, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>[missing, information, on, how, to, use, it, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>[very, nice, set, good, quality, we, have, had...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [love, this, well, made, sturdy, and, very, co...  \n",
       "1  [love, it, a, great, upgrade, from, the, origi...  \n",
       "2  [this, pillow, saved, my, back, i, love, the, ...  \n",
       "3  [missing, information, on, how, to, use, it, b...  \n",
       "4  [very, nice, set, good, quality, we, have, had...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stopword Removal**\n",
    "\n",
    "- **Eliminating common words** (e.g., \"and,\" \"the\") that do not add significant meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>[love, well, made, sturdy, comfortable, love, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>[love, great, upgrade, original, ive, mine, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>[pillow, saved, back, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>[missing, information, use, great, product, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>[nice, set, good, quality, set, two, months]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [love, well, made, sturdy, comfortable, love, ...  \n",
       "1  [love, great, upgrade, original, ive, mine, co...  \n",
       "2    [pillow, saved, back, love, look, feel, pillow]  \n",
       "3  [missing, information, use, great, product, pr...  \n",
       "4       [nice, set, good, quality, set, two, months]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking data of commonly considered stop words in english language as an array.\n",
    "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "df6 = df5.copy()\n",
    "\n",
    "df6['tokens'] = df6['tokens'].apply(lambda x:[word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "df6.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stemming/Lemmatization**\n",
    "\n",
    "- **Reducing words to their root or base form** (e.g., \"running\" → \"run\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Stemming** We reduce a word to it's root form by removing prefixes and suffixes. It may always not result in valid word.\n",
    "\n",
    "- eg: \"Running\" -> \"Runn\" and,\"Happily\" -> \"Happi\".\n",
    "\n",
    "- **Lemmatization** We reduce word to base or dictionary form. It takes in the meaning of the word. It always results in a valid word, but it is slower and more complex than stemming.\n",
    "\n",
    "- In this particular process, I am going ahead with Lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#We use Wordnet Lemmatizer with help of NLTK (Natural Language ToolKit)\n",
    "\n",
    "#Download Wordnet through NLTK.\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Create lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>[love, well, made, sturdy, comfortable, love, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>[love, great, upgrade, original, ive, mine, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>[pillow, saved, back, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>[missing, information, use, great, product, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>[nice, set, good, quality, set, two, month]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [love, well, made, sturdy, comfortable, love, ...  \n",
       "1  [love, great, upgrade, original, ive, mine, co...  \n",
       "2    [pillow, saved, back, love, look, feel, pillow]  \n",
       "3  [missing, information, use, great, product, pr...  \n",
       "4        [nice, set, good, quality, set, two, month]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = df6.copy()\n",
    "\n",
    "df7['tokens'] = df7['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\manth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>[love, well, make, sturdy, comfortable, love, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>[love, great, upgrade, original, ive, mine, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>[pillow, save, back, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>[miss, information, use, great, product, price]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>[nice, set, good, quality, set, two, month]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [love, well, make, sturdy, comfortable, love, ...  \n",
       "1  [love, great, upgrade, original, ive, mine, co...  \n",
       "2     [pillow, save, back, love, look, feel, pillow]  \n",
       "3    [miss, information, use, great, product, price]  \n",
       "4        [nice, set, good, quality, set, two, month]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We notice above, certain words are not reduced like from missing to miss, this is because we are only treating the token words as nouns, so in order to make accurate reduction to lemma, we have to use POS tags (Part of Speech tags).\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "#Corpus is large collection of text used for NLP. \n",
    "#Wordnet is such corpus which groups words into sets of synonyms called synsets.\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "#APT is pretrained POS tagger in NLTK\n",
    "\n",
    "#We map word's POS tag to format that WordNetLemmatizer accepts\n",
    "def get_wordnet_pos(word):\n",
    "    #Map POS tag to first character lemmatize() accepts\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\":wordnet.ADJ,\"N\":wordnet.NOUN,\"V\":wordnet.VERB,\"R\":wordnet.ADV}\n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n",
    "\n",
    "#Above function explanation, if we input word running, it returns [('running','VBG')] which is verb in present participle form. so we take indexing to get the first letter of the POS tag which is V. First 0 is to take tuple out from list, then 1 for POS tag, and 0 for first letter. Convert to upper case for uniformity.\n",
    "#Default return tag is noun, if there is no tag found in the tag_dict\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df8 = df7.copy()\n",
    "\n",
    "df8['tokens'] = df8['tokens'].apply(lambda x : [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in x])\n",
    "\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vectorization**\n",
    "\n",
    "- **Converting text data into numerical formats** (e.g., TF-IDF or word embeddings) suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bag of Words (BoW)** Convert text into vector of word counts. \n",
    "- Eg: We have \n",
    "    - Sentences\n",
    "        - \"I love machine learning\" \n",
    "        - \"Machine learning is fun\"\n",
    "        - \"I love fun\"\n",
    "    - Vocabulary\n",
    "        - [\"I\",\"love\",\"machine\",\"learning\",\"is\",\"fun\"]\n",
    "    - Vectors\n",
    "        - [1,1,1,1,0,0]\n",
    "        - [0,0,1,1,1,1]\n",
    "        - [1,1,0,0,0,1]\n",
    "\n",
    "- **TF-IDF (Term Frequency - Inverse Document Frequency)** Measure word importance in document.\n",
    "- Working:\n",
    "    - **TF**: Frequency of word in document\n",
    "    - **IDF**: How rare it is across all documents.\n",
    "    - The formula is:\n",
    "  $$ \\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\log \\left( \\frac{N}{\\text{DF}(t)} \\right) $$\n",
    "    - **TF(t, d)** is term frequency\n",
    "  $$ \\text{TF}(t, d) = \\frac{\\text{count of } t \\text{ in document } d}{\\text{total number of terms in document } d} $$\n",
    "    - **DF(t)** is the document frequency, representing the number of documents containing the term **t**.\n",
    "    - **N** is the total number of documents.\n",
    "- A unique word may have high IDF, and a common word may have low IDF, they get lower weight across documents.\n",
    "\n",
    "-Eg: * **Documents**:\n",
    "   1. **[i love machine learning]**\n",
    "   2. **[machine learning is fun]**\n",
    "   3. **[i love fun]**\n",
    "\n",
    "* **Step 1: TF (Term Frequency)**:\n",
    "   - For Document 1: **[i love machine learning]**:\n",
    "     - TF(\"i\") = 1/4 = 0.25\n",
    "     - TF(\"love\") = 1/4 = 0.25\n",
    "     - TF(\"machine\") = 1/4 = 0.25\n",
    "     - TF(\"learning\") = 1/4 = 0.25\n",
    "   - For Document 2: **[machine learning is fun]**:\n",
    "     - TF(\"machine\") = 1/4 = 0.25\n",
    "     - TF(\"learning\") = 1/4 = 0.25\n",
    "     - TF(\"is\") = 1/4 = 0.25\n",
    "     - TF(\"fun\") = 1/4 = 0.25\n",
    "   - For Document 3: **[i love fun]**:\n",
    "     - TF(\"i\") = 1/3 = 0.33\n",
    "     - TF(\"love\") = 1/3 = 0.33\n",
    "     - TF(\"fun\") = 1/3 = 0.33\n",
    "\n",
    "* **Step 2: IDF (Inverse Document Frequency)**:\n",
    "   - **Total documents (N) = 3**\n",
    "   - IDF(\"i\") = log(3/2) = 0.1761\n",
    "   - IDF(\"love\") = log(3/2) = 0.1761\n",
    "   - IDF(\"machine\") = log(3/2) = 0.1761\n",
    "   - IDF(\"learning\") = log(3/2) = 0.1761\n",
    "   - IDF(\"is\") = log(3/1) = 0.4771\n",
    "   - IDF(\"fun\") = log(3/2) = 0.1761\n",
    "\n",
    "* **Step 3: TF-IDF (Term Frequency - Inverse Document Frequency)**:\n",
    "   - For Document 1:\n",
    "     - TF-IDF(\"i\") = 0.25 * 0.1761 = 0.0440\n",
    "     - TF-IDF(\"love\") = 0.25 * 0.1761 = 0.0440\n",
    "     - TF-IDF(\"machine\") = 0.25 * 0.1761 = 0.0440\n",
    "     - TF-IDF(\"learning\") = 0.25 * 0.1761 = 0.0440\n",
    "   - For Document 2:\n",
    "     - TF-IDF(\"machine\") = 0.25 * 0.1761 = 0.0440\n",
    "     - TF-IDF(\"learning\") = 0.25 * 0.1761 = 0.0440\n",
    "     - TF-IDF(\"is\") = 0.25 * 0.4771 = 0.1193\n",
    "     - TF-IDF(\"fun\") = 0.25 * 0.1761 = 0.0440\n",
    "   - For Document 3:\n",
    "     - TF-IDF(\"i\") = 0.33 * 0.1761 = 0.0587\n",
    "     - TF-IDF(\"love\") = 0.33 * 0.1761 = 0.0587\n",
    "     - TF-IDF(\"fun\") = 0.33 * 0.1761 = 0.0587\n",
    "- Vector\n",
    "    - [1.0, 1.18, 1.48, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    - [1.0, 1.18, 0.0, 1.48, 0.0, 0.0, 0.0, 0.0]\n",
    "    - [1.0, 0.0, 0.0, 0.0, 1.48, 1.48, 1.48, 1.48]\n",
    "\n",
    "- **Word Embeddings (Word2Vec, GloVe)** Represents words as dense vectors in continuous space.\n",
    "- Pre-trained models are used to map words to high-dimensional vectors. Similar words are closer in vector space.\n",
    "- Eg: \"king\" - \"man\" + \"woman\" = \"queen\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love well make sturdy comfortable love itvery ...</td>\n",
       "      <td>[love, well, make, sturdy, comfortable, love, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love great upgrade original ive mine couple year</td>\n",
       "      <td>[love, great, upgrade, original, ive, mine, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>pillow save back love look feel pillow</td>\n",
       "      <td>[pillow, save, back, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>miss information use great product price</td>\n",
       "      <td>[miss, information, use, great, product, price]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>nice set good quality set two month</td>\n",
       "      <td>[nice, set, good, quality, set, two, month]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  love well make sturdy comfortable love itvery ...   \n",
       "1   love great upgrade original ive mine couple year   \n",
       "2             pillow save back love look feel pillow   \n",
       "3           miss information use great product price   \n",
       "4                nice set good quality set two month   \n",
       "\n",
       "                                              tokens  \n",
       "0  [love, well, make, sturdy, comfortable, love, ...  \n",
       "1  [love, great, upgrade, original, ive, mine, co...  \n",
       "2     [pillow, save, back, love, look, feel, pillow]  \n",
       "3    [miss, information, use, great, product, price]  \n",
       "4        [nice, set, good, quality, set, two, month]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For this particular scenario, I am using TF IDF. Since, we do not require too much complexity as is involved in Word2Vec and is also computationally less heavy.\n",
    "\n",
    "df9 = df8.copy()\n",
    "\n",
    "df9['text_'] = df9['tokens'].apply(lambda x: ' '.join(x))\n",
    "df9.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>rating</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016201</td>\n",
       "      <td>-0.958625</td>\n",
       "      <td>-1.034785</td>\n",
       "      <td>0.479430</td>\n",
       "      <td>-0.575406</td>\n",
       "      <td>-0.685280</td>\n",
       "      <td>0.596890</td>\n",
       "      <td>0.728719</td>\n",
       "      <td>-1.069964</td>\n",
       "      <td>0.092817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279581</td>\n",
       "      <td>0.951936</td>\n",
       "      <td>-0.171093</td>\n",
       "      <td>0.888181</td>\n",
       "      <td>-1.025417</td>\n",
       "      <td>0.452089</td>\n",
       "      <td>0.464295</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063518</td>\n",
       "      <td>-0.075566</td>\n",
       "      <td>-0.395096</td>\n",
       "      <td>0.501121</td>\n",
       "      <td>-0.865776</td>\n",
       "      <td>-0.603348</td>\n",
       "      <td>-0.331116</td>\n",
       "      <td>0.885015</td>\n",
       "      <td>-0.579975</td>\n",
       "      <td>-0.102530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139194</td>\n",
       "      <td>0.206701</td>\n",
       "      <td>0.184619</td>\n",
       "      <td>-0.055229</td>\n",
       "      <td>-0.547976</td>\n",
       "      <td>-0.335931</td>\n",
       "      <td>1.016516</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.249049</td>\n",
       "      <td>-0.503783</td>\n",
       "      <td>-0.492904</td>\n",
       "      <td>0.262155</td>\n",
       "      <td>0.324256</td>\n",
       "      <td>-0.496594</td>\n",
       "      <td>0.643460</td>\n",
       "      <td>0.824033</td>\n",
       "      <td>-1.163048</td>\n",
       "      <td>-0.374925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780556</td>\n",
       "      <td>0.737468</td>\n",
       "      <td>-0.101524</td>\n",
       "      <td>-0.088016</td>\n",
       "      <td>-1.093231</td>\n",
       "      <td>0.277394</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.034140</td>\n",
       "      <td>0.517855</td>\n",
       "      <td>-0.499791</td>\n",
       "      <td>1.418628</td>\n",
       "      <td>0.044079</td>\n",
       "      <td>-0.726697</td>\n",
       "      <td>-0.093427</td>\n",
       "      <td>0.983345</td>\n",
       "      <td>-0.813905</td>\n",
       "      <td>-0.667083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459059</td>\n",
       "      <td>1.233730</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>-0.025329</td>\n",
       "      <td>-0.926069</td>\n",
       "      <td>-0.243112</td>\n",
       "      <td>-0.425895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.505681</td>\n",
       "      <td>-0.273524</td>\n",
       "      <td>-0.877795</td>\n",
       "      <td>0.597551</td>\n",
       "      <td>-0.688114</td>\n",
       "      <td>0.050559</td>\n",
       "      <td>-0.141156</td>\n",
       "      <td>1.116429</td>\n",
       "      <td>-0.757271</td>\n",
       "      <td>-0.214179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507116</td>\n",
       "      <td>0.564768</td>\n",
       "      <td>0.196237</td>\n",
       "      <td>-0.112224</td>\n",
       "      <td>-1.039660</td>\n",
       "      <td>-0.470514</td>\n",
       "      <td>0.636248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.016201 -0.958625 -1.034785  0.479430 -0.575406 -0.685280  0.596890   \n",
       "1  0.063518 -0.075566 -0.395096  0.501121 -0.865776 -0.603348 -0.331116   \n",
       "2  0.249049 -0.503783 -0.492904  0.262155  0.324256 -0.496594  0.643460   \n",
       "3 -0.034140  0.517855 -0.499791  1.418628  0.044079 -0.726697 -0.093427   \n",
       "4 -0.505681 -0.273524 -0.877795  0.597551 -0.688114  0.050559 -0.141156   \n",
       "\n",
       "          7         8         9  ...        93        94        95        96  \\\n",
       "0  0.728719 -1.069964  0.092817  ...  0.279581  0.951936 -0.171093  0.888181   \n",
       "1  0.885015 -0.579975 -0.102530  ... -0.139194  0.206701  0.184619 -0.055229   \n",
       "2  0.824033 -1.163048 -0.374925  ...  0.780556  0.737468 -0.101524 -0.088016   \n",
       "3  0.983345 -0.813905 -0.667083  ...  0.459059  1.233730  0.413352 -0.025329   \n",
       "4  1.116429 -0.757271 -0.214179  ...  0.507116  0.564768  0.196237 -0.112224   \n",
       "\n",
       "         97        98        99  rating            category  label  \n",
       "0 -1.025417  0.452089  0.464295     5.0  Home_and_Kitchen_5     CG  \n",
       "1 -0.547976 -0.335931  1.016516     5.0  Home_and_Kitchen_5     CG  \n",
       "2 -1.093231  0.277394  0.007453     5.0  Home_and_Kitchen_5     CG  \n",
       "3 -0.926069 -0.243112 -0.425895     1.0  Home_and_Kitchen_5     CG  \n",
       "4 -1.039660 -0.470514  0.636248     5.0  Home_and_Kitchen_5     CG  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "#Word2Vec model\n",
    "model = Word2Vec(\n",
    "    sentences = df9['tokens'], #Tokenised data as input\n",
    "    vector_size = 100, # Dimension of word vector\n",
    "    window = 5, # Context window size for words\n",
    "    min_count = 1\n",
    ")\n",
    "\n",
    "def get_average_word2vec(tokens_list,model,vector_size):\n",
    "    v = np.zeros(vector_size)\n",
    "    count = 0\n",
    "    for word in tokens_list:\n",
    "        if word in model.wv: # Check if word is in model's vocabulary\n",
    "            v +=model.wv[word]\n",
    "            count+=1\n",
    "    if count>0:\n",
    "        v/=count # Calculate average\n",
    "    return v\n",
    "\n",
    "df9['word2vec'] = df9['tokens'].apply(lambda x: get_average_word2vec(x,model,model.vector_size))\n",
    "\n",
    "df10 = pd.DataFrame(df9['word2vec'].tolist(), index = df9.index)\n",
    "\n",
    "df11 = df10.join(df9[['rating','category','label']])\n",
    "\n",
    "df11.head()\n",
    "\n",
    "# #TfidfVectorizer used to convert text to matrix\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# #Initialise object\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(df9['text_'])\n",
    "# #Fit -> Learns vocabulary, Transform -> Convert text to TF-IDF Matrix\n",
    "\n",
    "# # We use sparse matrix since it allows us to handle data where most values are 0 without using too much memory.\n",
    "# #Converting it to a denser NumPy array causes Memory Limit to Exceed, for this particular dataset, i need to provide it with more than 12 Gigabytes of memory, The obtained MemoryError is Unable to allocate 12.0 GiB for an array with shape (40420, 39836) and data type float64\n",
    "\n",
    "\n",
    "# # get_feature_names_out() -> get list of word names corresponding to columns of TF IDF matrix\n",
    "# df10 = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix,columns=tfidf_vectorizer.get_feature_names_out())\n",
    "# df10.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df11.copy()\n",
    "# df9 = df9.reset_index(drop = True)\n",
    "# df_final = df_final.reset_index(drop = True)\n",
    "\n",
    "# df_final['category'] = df9['category']\n",
    "# df_final['rating'] = df9['rating']\n",
    "# df_final['label'] = df9['label']\n",
    "# df_final['text_'] = df9['text_']\n",
    "# df_final['tokens'] = df9['tokens']\n",
    "\n",
    "# print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('Processed_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
